# -*- coding: utf-8 -*-
"""Group_28_SportsPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O1Wfuu4bjO49G0j16yEPV7eYRSpqNrTU

## Question 1.

# Sports Prediction

Sports Prediction

In sports prediction, large numbers of factors including the historical performance of the teams, results of matches, and data on players, have to be accounted for to help different stakeholders understand the odds of winning or losing.

## Data Preparation and Feature Extraction
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Import statements
import pandas as pd
import numpy as np
import random as rnd

# Encoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

# Imputer
from sklearn.impute import KNNImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Visualization
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

# Models
from sklearn.feature_selection import RFECV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# loading the datasets with low_memory param set to false
# Pandas will attempt to load the entire dataset into memory at once
players_df = pd.read_csv("/content/drive/My Drive/Colab Notebooks/players_21.csv", low_memory=False)

# We'll clean up the '21 dataframe simultaneously
test_df = pd.read_csv("/content/drive/My Drive/Colab Notebooks/players_22.csv", low_memory=False)

# show dataframe head
players_df.head()

# We don't need the player urls so we'll delete those
players_df = players_df[players_df.columns.drop(list(players_df.filter(regex='url')))]
test_df = test_df[test_df.columns.drop(list(test_df.filter(regex='url')))]

"""### Missing entries

Missing entries are problematic when it comes to training a prediction model. These missing values could skew the model to over or underfit on the training data thereby giving us inaccurate predictions.
"""

# We need to worry about missing entries
# Suppose a column has at least half of its rows empty, we'll drop them

cols_with_more_than_half_entries_missing = []

for i in players_df.columns:
    missing_entries = np.abs((players_df[i].count() - players_df[i].shape[0])/players_df[i].shape[0] * 100)
    if missing_entries > 50:
        cols_with_more_than_half_entries_missing.append(i)

# Display the name of the columns with a lot of missing entries
print(cols_with_more_than_half_entries_missing)

# From above, we can see the various columns that have a lot of missing entries
# We need to drop them from the dataset
players_df.drop(columns = cols_with_more_than_half_entries_missing, inplace=True)
test_df.drop(columns = cols_with_more_than_half_entries_missing, inplace=True)

players_df.head()

"""From the results above, we can see that we have 97 columns now instead of the initial 110 we started with. This process of elimination will help us narrow down our dataset and leave us with columns that will be relevant for training."""

# The next code block will drop some columns based on prefixes
# We will need the 'skill_moves' column so we will rename it to 'skill'
players_df.rename(columns = {'skill_moves':'skill'}, inplace=True)
test_df.rename(columns = {'skill_moves':'skill'}, inplace=True)

# We want to still narrow our dataset down to mostly relevant columns
# We'll use the following filter to drop some more columns

# We will be dropping columns that have the following prefixes
# Overall player ratings are seldom dependent on these
regex_filter = ['sofifa_id','skill_','movement_','defending_','goalkeeping_','attacking_','power_','mentality_']

for i in regex_filter:
    players_df = players_df[players_df.columns.drop(list(players_df.filter(regex=i)))]
    test_df = test_df[test_df.columns.drop(list(test_df.filter(regex=i)))]
#Determining how may columns we have left
print(f"We now have {players_df.shape[1]} columns to work with\n")
print(players_df.columns)

# We notice from the results above that from 'ls' to 'rb' are player positions
# For shortness, we will take the columns from 'short_name' to 'physic'

roles = ['short_name','age','height_cm','weight_kg','nationality_name','club_name','overall','potential','league_name','league_level',
          'value_eur','wage_eur','player_positions','preferred_foot','international_reputation',
          'skill', 'work_rate', 'pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic']

non_positions = players_df[roles]

tnpos = test_df[roles]

positions = non_positions['player_positions'].value_counts().head(20)

tpos = tnpos['player_positions'].value_counts().head(20)

# We will now check what rows are empty
# if the sum is anything other than '0', then there are missing rows in that column

non_positions.isnull().sum()

# Most player positions have rw, st, or cf in their name
# We can assume that all the above fall under rw
non_positions['player_positions'] = non_positions['player_positions'].apply(lambda x: x.split(',')[0].strip())
tnpos['player_positions'] = tnpos['player_positions'].apply(lambda x: x.split(',')[0].strip())

# We can now obtain a set (more like a list) of unique positions
unique_positions = non_positions['player_positions'].unique()
tdf_unique = tnpos['player_positions'].unique()

# Next, instead of pestering our model with more nominal data
# We can simplify the training by using 'league_level' instead of
# league_name, club_name, nationality_name or short_name

non_positions = non_positions.drop(columns=['nationality_name', 'club_name', 'league_name', 'short_name'])
tnpos = tnpos.drop(columns=['nationality_name', 'club_name', 'league_name', 'short_name'])

"""# Question 2
### Data preprocessing

This section mostly deals with trying to convert/encode typical categorical data into integer forms that will be easier to train with.

For starters, the `preferred_foot` column can be encoded into binary data using a OneHotEncoder. Afterall, it has only two categorical values, i.e. right foot or left foot. We could encode it such that **right foot** is `0` and **left foot** is `1`.
"""

bin_encoder = OneHotEncoder(sparse = False)

_encoded = bin_encoder.fit_transform(non_positions[['preferred_foot']])
tdf_encoded = bin_encoder.fit_transform(tnpos[['preferred_foot']])

encoded_data = pd.DataFrame(_encoded, columns = bin_encoder.categories_[0])
tdf_endata = pd.DataFrame(tdf_encoded, columns = bin_encoder.categories_[0])

data_encoded = pd.concat([non_positions, encoded_data], axis = 1)
tdf_datencoded = pd.concat([tnpos, tdf_endata], axis = 1)

data_encoded

"""We can use `LabelEncoder` to encode all the categorical columns in the `data_encoded` dataframe as integers. This allows for easier processing by algorithms."""

label_encoder = LabelEncoder()

for i in data_encoded.select_dtypes(['object']):
    data_encoded[i] = label_encoder.fit_transform(data_encoded[i])

for j in tdf_datencoded.select_dtypes(['object']):
    tdf_datencoded[j] = label_encoder.fit_transform(tdf_datencoded[j])


data_encoded.info()

# What we expect to see are most of the columns data type
# switching from 'Object' to 'int64'

"""#### Missing Values

Above, we examined how many missing entries we had present in the dataset. We dropped some and saved some columns. The remaining columns however are crucial for the prediction model we're trying to develop, hence, we'll use `KNNImputer` to attempt to impute the missing values.
"""

cols_w_missing_vals = data_encoded.columns[data_encoded.isnull().any()].tolist()
tdf_cwmv = tdf_datencoded.columns[tdf_datencoded.isnull().any()].tolist()

imputed = data_encoded.copy()
tdf_imp = tdf_datencoded.copy()

imput_data = imputed[cols_w_missing_vals].copy()
tdf_impdata = tdf_imp[tdf_cwmv].copy()

imputer = KNNImputer(n_neighbors = 6)

imputed_data = imputer.fit_transform(imput_data)
tdf_id = imputer.fit_transform(tdf_impdata)

imputed[cols_w_missing_vals] = imputed_data
tdf_imp[tdf_cwmv] = tdf_id

# Checking to see if there are any missing rows now
imputed.isnull().sum()

# We will now convert the remaining float64 columns into neat int64 columns
f_cols = imputed.select_dtypes(include=['float']).columns
dtf_cols = tdf_imp.select_dtypes(include=['float']).columns

imputed[f_cols] = imputed[f_cols].astype(int)
tdf_imp[dtf_cols] = tdf_imp[dtf_cols].astype(int)

tdf_imp['player_positions'] = tdf_imp['player_positions'].astype(int)
#tdf_imp['preferred_foot'] = tdf_imp['preferred_foot'].astype(int)

tdf_imp.info()

"""#Question 3 & Question 4
## Prediction

We're done tidying up the dataset. We've eliminated as many uncertain variables that might result in an inaccurate model. We're now confronted with the challenge of picking a model to work with.

The best contenders for the job are models that can toe the line between regression and classification. In our case, our goal is to 'predict' a new set of values based on old ones, this is a heavily-regression-based problem.

Our options are thus `LinearRegression`, `RandomForrest` and `K-Nearest Neighbors`. For the sake of simplicity, we'll only consider LinearRegression and RandomForrest and compare their performances.

#### Training with Linear Regression

For this, we need to select the optimal subset of features for a linear regression model. We can do this using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm.
"""

# We'll drop 'overall' since its the target feature and 'potential'
# We're dropping potential simply because its way too closely related to overall
X = imputed.drop(columns=['overall', 'potential'])
tdf_X = tdf_imp.drop(columns=['overall', 'potential'])

y = imputed['overall']
tdf_y = tdf_imp['overall']

lr_model = LinearRegression()
rfecv = RFECV(estimator=lr_model, scoring='neg_mean_squared_error')

X_selected = rfecv.fit_transform(X, y)
selected_features = X.columns[rfecv.support_]

print(f"Number of optimal features: {rfecv.n_features_}\n{selected_features}")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# We'll create the regression model using a pipeline that includes
# a StandardScaler object for feature scaling and
# a LinearRegression object for modelling

pipeline = Pipeline([
    ('standardscaler', StandardScaler()),
    ('linearregression', LinearRegression())
])

pipeline.fit(X_train, y_train)

y_pred_test = pipeline.predict(X_test)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_test = np.sqrt(mse_test)
r2_test = r2_score(y_test, y_pred_test)
print(f'Mean Squared Error(MSE) test:{mse_test:.4f}')
print(f'Root Mean Squared Error (RMSE) test:{rmse_test:.4f}')
print(f'R-squared test:{r2_test:.4f}\n{"="*40}')
y_pred = pipeline.predict(X)
mse = mean_squared_error(y, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y, y_pred)
print(f'Mean Squared Error(MSE) all:{mse:.4f}')
print(f'Root Mean Squared Error (RMSE) all:{rmse:.4f}')
print(f'R-squared all:{r2:.4f}')

print(f"\nCoeff Of Determination (Accuracy): {(pipeline.score(X_test, y_test) * 100):.4f}%")

"""#### Training with RandomForrest"""

# Over here, we'll create another regression model using the
# RandomForestRegressor object

rf = RandomForestRegressor(random_state=42)


rf.fit(X_train, y_train)


y_pred_test_rfg = rf.predict(X_test)

mse_test_rf = mean_squared_error(y_test, y_pred_test_rfg)
rmse_test_rf = np.sqrt(mse_test_rf)
r2_test_rf = r2_score(y_test, y_pred_test_rfg)

y_pred_neigh_acc = neigh.predict(X)
y_pred_rfg = rf.predict(X)
mse_all_rf = mean_squared_error(y, y_pred_rfg)
rmse_all_rf = np.sqrt(mse_all_rf)
r2_all_rf = r2_score(y, y_pred_rfg)

print(f'Mean Squared Error(MSE) test:{mse_test_rf:.4f}')
print(f'Root Mean Squared Error (RMSE) test:{rmse_test_rf:.4f}')
print(f'R-squared test:{r2_test_rf:.4f}\n{"="*40}')
print(f'Mean Squared Error(MSE) all:{mse_all_rf:.4f}')
print(f'Root Mean Squared Error (RMSE) all:{rmse_all_rf:.4f}')
print(f'R-squared all:{r2_all_rf:.4f}')

print(f"\nCoeff Of Determination (Accuracy): {(rf.score(X_test, y_test) * 100):.4f}%")

"""#### Training with KNNRegressor"""

# Here we'll create a K-Nearest Neighbour Regressor

neigh = KNeighborsRegressor(n_neighbors=7)
neigh.fit(X_train, y_train)

y_pred_neigh = neigh.predict(X_test)

mse_test_neigh = mean_squared_error(y_test, y_pred_neigh)
rmse_test_neigh = np.sqrt(mse_test_neigh)
r2_test_neigh = r2_score(y_test, y_pred_neigh)


y_pred_neigh_acc = rf.predict(X)
mse_all_neigh = mean_squared_error(y, y_pred_neigh_acc)
rmse_all_neigh = np.sqrt(mse_all_neigh)
r2_all_neigh = r2_score(y, y_pred_neigh_acc)

print(f'Mean Squared Error(MSE) test:{mse_test_neigh:.4f}')
print(f'Root Mean Squared Error (RMSE) test:{rmse_test_neigh:.4f}')
print(f'R-squared test:{r2_test_neigh:.4f}\n{"="*40}')
print(f'Mean Squared Error(MSE) all:{mse_all_neigh:.4f}')
print(f'Root Mean Squared Error (RMSE) all:{rmse_all_neigh:.4f}')
print(f'R-squared all:{r2_all_neigh:.4f}')

print(f"\nCoeff Of Determination (Accuracy): {(neigh.score(X_test, y_test) * 100):.4f}%")

"""## Comparing the models

We now have functioning models that could be used to predict the overall ratings of a football player based on certain 16 features. We'd like to now see which model was more effective for the purposes we required.

We can do this by comparing their various metrics in an algorithm and dataset analysis application like `WEKA` or we could plot the predicted versus real values of each model and see which delivers the best results.
"""

data1 = pd.DataFrame({'Real': y_test, 'Predicted': y_pred_test})

sns.scatterplot(data=data1, x='Real', y='Predicted')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)
plt.xlabel('Real')
plt.ylabel('Predicted')
plt.title("LinearRegression model")
plt.show()

data2 = pd.DataFrame({'Real': y_test, 'Predicted': y_pred_test_rfg})

sns.scatterplot(data=data2, x='Real', y='Predicted')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)
plt.xlabel('Real')
plt.ylabel('Predicted')
plt.title("RandomForest model")
plt.show()

data3 = pd.DataFrame({'Real': y_test, 'Predicted': y_pred_neigh})

sns.scatterplot(data=data3, x='Real', y='Predicted')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)
plt.xlabel('Real')
plt.ylabel('Predicted')
plt.title("KNN Regressor")
plt.show()

"""Going by the scatter plots above, we observe that the randomforest model fares better than the linear regression model since the points stay close to the line of regression. Thus we can conclude the the model for the job is `RandomForest` as per our analysis.

#Question 5
### Testing the RF Model on the 2022 Dataset
"""

from sklearn.metrics import accuracy_score

tdf_pred = rf.predict(tdf_X)

data3 = pd.DataFrame({'Real': tdf_y, 'Predicted': tdf_pred})

sns.scatterplot(data=data3, x='Real', y='Predicted')
plt.plot([tdf_y.min(), tdf_y.max()], [tdf_y.min(), tdf_y.max()], 'r--', lw=3)
plt.xlabel('Real')
plt.ylabel('Predicted')
plt.title("Test using '22 Dataset")
plt.show()

print(f"Mean Squared Error: {mean_squared_error(tdf_y, tdf_pred):.4f}")
print(f"Coefficient of Determination: {(rf.score(tdf_X, tdf_y) * 100):.4f}%")

"""### Saving the model using Pickle"""

import pickle
import bz2

# saving as random_forest_regression_model
pkl_file = "model.pkl"
oFile = bz2.BZ2File(pkl_file, 'wb')
pickle.dump(rf, oFile)
oFile.close()

